### **What Does a Computer Understand?**
- Computer does not understand natural human language, nor programming languages.
- They only understand the lanuage of bits (0s and 1s).
- **Bit :** A variable that can have two values: 0 or 1.
- **Byte :** A sequence of 8 bits. (1byte = 8 bits).
- **Word :** 4 bytes.
- **kiloBytes** : 1024 bytes = 2<sup>10</sup> bytes.
- **megaBytes :** 1024 kiloBytes = 10 <sup>6</sup> Bytes. = 2<sup>20</sup> bytes.
- We shall see that it is very easy to store, retrieve and process billions of 0s and 1s. Secondly, existing technologies to implement computers using silicon transistors are very compatible with the notion of processing 0s and 1s.
- A basic silicon transistor is a switch that can set the output to a logical 0 or 1, based on the input. The silicon transistor is the basis of all the electronic computers that we have today right from processors in mobile phones to processors in supercomputers.
---

### **Binary**
- Binary representation is the way numbers, data, or instructions are expressed using only two symbols: 0 and 1.
- Binary variables (0 or 1) were first described by George Boole in 1854. He used such variables and their associated operations to describe logic in a mathematical sense. He defined a full algebra consisting of simple binary variables, along with a new set of operators, and basic operations. 
- In the honour of George Boole, a binary variable is also known as a Boolean variable, and an algebraic system of Boolean variables is known as Boolean algebra.

---
### **Logical Operation**
 **NOT Operation**
- operator  represented by - NOT , bar (-) ,  !  , complement ( \` ).
- NOT A , if a is false then true and true then false.
- ![[Pasted image 20241119095641.png]]
	
**OR Operation**
- operator represented by - OR , + , v .
- A OR B , if both value are false (0) then false (0) otherwise true (1).
- ![[Pasted image 20241119092654.png]]
 **AND Operation**
- operator represented by - AND , dot(.) , ^.
- A AND B , if both value are true(1) then true(1) otherwise false (0).
- ![[Pasted image 20241119093501.png]]
 **NAND and NOR Operation**
- Derived Operators
- NAND = complement of AND  (NOT of AND).
- NOR = complement of OR (NOT of OR).
- These are universal operators . They can be used to implement any boolean function. 
- ![[Pasted image 20241119101845.png]]
- ![[Pasted image 20241119101955.png]]

**XOR Operation**
- Aka Exculsive OR
- Operator represented by - XOR , ⊕ .
- A XOR B , if both same then false (0) else true (1).
- ![[Pasted image 20241119103509.png]]

---

### **Rules of Boolean algebra (Properties)**
**NOT Operator**
- NOT of 0 = 1 , NOT of 1 = 0.
- Not of (Not of A) = A.
**OR and AND Operator**
- Identity : A + 0 = A  and A . 1 = A {where + means OR , . means AND}.
- Annulment : A + 1 = 1 and A . 0 = 0.
- Idempotence : A + A = A and A . A = A.
- Complementary : A + A̅ = 1 and A . A̅ = 0.
- Comutativity : A + B = B + A and  A . B = B . A , order doesn't matter.
- Associativity :  A + (B + C) = (A + B) + C and A . (B . C) = (A . B) . C.
- Distributivity : A . (B + C) = A.B + A.C and A+ B.C = (A + B) .(A + C).
**De-morgan Laws**
- <span style="text-decoration: overline;">A + B</span> = A̅ . B̅  , NOT of (A OR B) = (NOT of A) AND (NOT of B). 
- <span style="text-decoration: overline;">A . B</span> = A̅ + B̅  , NOT of (A AND B) = (NOT of A ) OR (NOT of B).
**Questions :**
- Prove the consensus theorem: X.Y + X̅.Z + Y.Z = X.Y + X̅.Z.
- Prove the theorem: (X + Z).(X̅ + Y ) = X.Y + X̅.Z.

---
### **Logic Gates**
- A logic gate is a device that implements a Boolean function.
![[Pasted image 20241119150942.png]]
---

### **Implementing Boolean Functions / Simplification **
- Let us now consider a generic boolean function f(A, B, C . . .). To implement it we need to create a circuit out of logic gates. 
- Our aim should be to minimise the number of gates to save area, power, and time.
**Simple Method/Using Boolean Algebra**


**Karnaugh Maps**

---

### **Representing Positive Integer**
**Ancient Number Systems**
- Roman System : Symbol I, V, X, L, C, D ,M for Value 1, 5, 10, 50, 100, 500, 1000
-  Issues with roman system : There was no notion of 0, Very difficult to represent large numbers Addition, and subtraction (very difficult).
- Indian System : Bakhshali Manuscript![[Pasted image 20241119173117.png]]
- it use place value system : 5301 = 5 x 10<sup>3</sup> + 3 x 10 <sup>2</sup> + 0 x 10<sup>1</sup> + 1 x 10<sup>0</sup>
- means base 10 , using 10 digits to rep.
**Binay Number Systems**
- use number system with base 2, means using only two digits to represents a number.
- 5 (in base 10)= 1 x 2<sup>2</sup> + 0 x 2<sup>1</sup>+1 x 2<sup>0</sup> = 101 (in base 2)
- 500 (in base 10) = 111110100 (in base 2).
- MSB (Most Significant Bit) à The leftmost bit of a binary number. E.g., MSB of 1110 is 1
- LSB (Least Significant Bit) à The rightmost bit of a binary number. E.g.,  LSB of 1110 is 0

**Hexadecimal Number System
- Base 16 number - 0 , 1, 2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 , A , B , C , D , E , F.
- add 0x at the starting, for convention.
- Ex :  11 (base 10) = A (base 16) OR 0xA 
**Octal Number Systems
- Base 8 number - 0 ,1 , 2 , 3 , 4 , 5 , 6 , 7
- add 0 at the starting, for convention.
- Ex: 8 (base 10) = 10(base 8) OR 010 
**Why use we study Binary , Hexa and Octal and not other system like base 7 or base 9**
- becuase we easly can convert binary to hexa and binary octal and wise-versa 
- Convert 110010111 to the octal format :  '110'  '010'  '111' = 627(base 8) = 0627 
- Convert 111000101111 to the hex format :  '1110' '0010' '1111' = E2F(base 16) = 0xE2F.
- In above example we easly convert binary to octal make 3-pair and binary to hexa making 4-pair of the binary digits , and  we also can convert reverse easily.

---
### **Representing Negative Number**
**signed manitude system**
- if n bits use to represent a number then 
- first bit from the left side use to present sign and unsined
- unsigned = negative = 1
- signed = postive = 0
- EX: in 4 bit number system
	- -5 = 1101
	-  5  = 0101
- ![[Pasted image 20241120115914.png]]
- problem
	- there are two representation for 0 , 0000 and 10000
	- addition and subtraction are difficult
**first complementry (1\`s)**
- 5 = 101 => -5 = 1111 - 101
- 0101 = 5 
- 1010 = -5
- 0000 = 0 
- 1111 = -0
- Easy to add +ve numbers.
- hard to ad -ve numbers
**bias based approach**
- f(u) = u + bias
- consider a 4 bit number system with bias equal to 7
- -3 = 0100 (7 -3 = 4)
-  3 = 1010 ( 7 + 3 =10) 
- addition - f (u + v) = F(u) + f(v) - bias
- subtraction - f(u -v) = f(u) - f(v) + bias
- multiplication is difficult
**number circle with negative numbers / 2's complements**
- conside use 4 bits to represent a number
- then 0000 , 0001 0010  0011 0100 0101 0110 0111 1000 1001 1010 1011 1100 1101 1110 1111
-           0     ,  1   ,    2   ,    3   ,   4    ,   5  ,    6   ,    7  ,    8    ,   9   ,  10  ,  11   ,  12  ,  13  , 1 4  ,   15
-  ==>  0    ,   1   ,    2   ,    3  ,    4    ,   5  ,   6   ,    7 ,    -8    ,  -7   ,  -6  ,  -5    ,  -4  ,  -3   ,  -2   ,   -1
- AKA 2's complement
- properties of 2's complements
	- range = -2<sup>n-1</sup> to 2<sup>n-1</sup> -1  , where n = using bits for number representation
	- there is a unique represenattion for 0 --> 00000
	- *msb of F(u) is equal to SgnBit(u)
	- Refer to the number circle
	- For a +ve number, F(u) < 2<sup>(n-1)</sup>. MSB = 0
	- For a -ve number, F(u) >= 2<sup>(n-1)</sup>. MSB = 1
	- Every number in the range [-2(n-1),2(n-1) – 1] Has a unique mapping Unique point in the number circle
	- f(-u) = 2<sup>n</sup> - f(u)
	- if v is a negative number then f(v) = 2<sup>n</sup> - | v |
	- f (u + v) = f (u) + f (v)
	- f(u * v) =  f (u) * f (v )
	- 1's complement + 1 = 2's complement
- Convert a n bit number to a m bit 2's complement number (m > n)
	- +ve :  Add (m-n) 0s in the msb positions , *Example, convert 0100 to 8 bits → 0000 0100
    - -ve : F(u) = 2<sup>n</sup> – |u| (n bit number) system , Need to calculate F'(u) = 2<sup>m</sup> -|u| ,                                =>  F'(u) = F(u) + 2<sup>m</sup> - 2<sup>n</sup> 
        in simple , Add (m-n) 1s in msb positions , Example ,convert 1100 to 8 bits → 1111 1100 
- The overflow theorem
	 - Add : u + v
	 - if uv < 0, there will never be an overflow
	 - Let us go back to the number circle , there is an overflow only when we cross the break-point 
	 - if uv = 0, one of the numbers is 0 (no overflow)
	 - if uv > 0, an overflow is possible (when u and v is same sign and result uv is diffrent sign)

---

### **Represenating Floating-Point Numbers**
**watch all about electronices**

#### 1. **Overview**

- Floating point numbers are used to store very large or very small numbers in computers, e.g., planetary masses or atomic constants.
- They provide a better range and precision compared to fixed-point numbers.

#### 2. **Fixed-Point Representation**

- **Definition:** The position of the radix (decimal) point is fixed.
- **Examples:**
    - Integers: Decimal point implied at the end of the number (e.g., `123` has no fractional part).
    - Real numbers: Decimal point separates integer and fractional parts (e.g., `11.75`).
- **Limitations:**
    - Limited range due to fixed allocation of bits for integer and fractional parts.
    - Precision and range are inversely related (e.g., increasing fractional bits reduces integer range).
- **Binary Representation:** Requires manual allocation of bits for integer and fractional parts.

#### 3. **Floating-Point Representation**

- **Key Advantage:** Allows dynamic shifting of the radix point to optimize range or precision.
- **Structure:** Comprises three parts:
    1. **Sign bit**: Indicates positive or negative number.
    2. **Exponent**: Adjusts the position of the radix point.
    3. **Mantissa (or Fraction)**: Stores the significant digits.
- **Scientific Notation Analogy:**
    - Decimal numbers: `4.345 × 10^-3` (Mantissa = `4.345`, Exponent = `-3`).
    - Binary numbers: Represented similarly, with the base `2`.
- **Normalization:** Ensures only one significant digit (`1`) before the binary point.

#### 4. **IEEE 754 Standard**

- Widely used standard for floating-point representation.
- Defines how to store floating-point numbers in varying bit formats:
    - **Half Precision:** 16 bits
    - **Single Precision:** 32 bits
    - **Double Precision:** 64 bits
    - Larger precisions: 128 and 256 bits.
- **Single Precision Format (32 bits):**
    - **Sign bit:** 1 bit
    - **Exponent:** 8 bits (uses biased representation , bias=127).
    - **Mantissa:** 23 bits.
    - **Range:** ~10^38 to ~10^-38.
    - **Precision:** Up to 7 decimal digits.
- **Double Precision Format (64 bits):**
    - **Sign bit:** 1 bit
    - **Exponent:** 11 bits (uses biased representation , bias = 1023).
    - **Mantissa:** 52 bits.
    - **Range:** ~10^308 to ~10^-308.
    - **Precision:** Up to 16 decimal digits.

### 5. **Exponent Representation**

- **Biased Representation:** Adds a bias to make negative exponents positive.
    - Example: For 8-bit exponent, bias = 127.
    - Range: Actual exponent = Stored value - Bias.
- **Advantages:** Continuity in representation simplifies number comparisons.

#### 6. **Comparison: Fixed-Point vs. Floating-Point**

- **Range:**
    - Fixed-point: Limited by bit allocation.
    - Floating-point: Greater range, supports extremely large/small values.
- **Precision:**
    - Fixed-point: Uniform precision but less flexible.
    - Floating-point: Flexible precision but limited to a certain number of digits.
- **Use Cases:**
    - Fixed-point: Applications requiring uniform precision (e.g., monetary calculations).
    - Floating-point: Scientific and engineering computations.

#### 7. **Key Calculations and Examples**

- Converting floating-point to decimal:
    - Extract sign, exponent, and mantissa.
    - Compute actual value by adjusting the radix point using the exponent.
- Converting decimal to IEEE 754 format:
    - Normalize binary representation.
    - Store sign, exponent (with bias), and mantissa.

#### 8. **Precision and Range Trade-Off**

- Floating-point increases range but sacrifices precision.
- Example: Single precision cannot accurately store numbers requiring more than 7 significant digits.

#### 9. **Special Cases in IEEE 754**

- Exponent values of all zeros or all ones are reserved for special purposes (e.g., representing infinity or NaN).
- ![[Pasted image 20241124103633.png]]

![[Pasted image 20241124105156.png]]
![[Pasted image 20241124105234.png]]
### 10. **Applications**

- Floating-point numbers are crucial in scientific calculations, graphics, and simulations where a wide range of values is essential.

This summary outlines the critical points covered in the subtitles, offering a concise reference for understanding binary floating-point representation.
![[Pasted image 20241124105626.png]]

---

### **Representing String**
**ASCII Character Set**
- ASCII - American Standard Code for Information Interchange
- It has 128 characters
- First 32 characters is  non-printable character(control operations)
	- 8 - backspace
	- 10 - line feed
	- 27 - escape
- Each Character is encoded using 7 bits 
- ![[Pasted image 20241124185837.png]]

**UTF - 8**
- Unicode Transformation Format - 8-bit
- The Unicode Standard is a universal character encoding system designed to represent text from all writing systems, symbols, and emojis in a consistent and interoperable way. It provides a unique code point for every character across languages, scripts, and symbols, enabling seamless text processing across platforms.
- use 1-4 bytes 
- formate
	- 1byte  ->  0xxxxxxx
	- 2bytes -> 110xxxxx 10xxxxxx
	- 3bytes ->  1110xxxx 10xxxxxx 10xxxxxx
	- 4bytes -> 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
- range 
- 0 to U+10FFFF
- 1 byte  -> 7 bits => 128
- 2 bytes -> 11 bits => 2048
- 3 bytes -> 16 bits => 65536
- 4 bytes -> 21 bits => 2,097,152,  but only code points up to U+10FFFF are valid. so valid                                             =1,114,112 but The surrogate pair range (`U+D800` to `U+DFFF`, 2,048 code                                       points) is reserved for UTF-16  = 1,114,112 - 2048 = 1,112,064

**UTF-16** and **UTF-32** are Unicode encoding formats, like UTF-8, but they differ in how they represent Unicode characters in terms of size and structure. Here's a detailed explanation:
### Comparison of UTF-8, UTF-16, and UTF-32

| **Aspect**          | **UTF-8**                                    | **UTF-16**                       | **UTF-32**                        |
| ------------------- | -------------------------------------------- | -------------------------------- | --------------------------------- |
| **Encoding Type**   | Variable-length (1-4 bytes)                  | Variable-length (2-4 bytes)      | Fixed-length (4 bytes)            |
| **Efficiency**      | Efficient for ASCII, space-efficient overall | Compact for many scripts         | Always uses 4 bytes per character |
| **Complexity**      | Simple decoding logic                        | Complex (due to surrogate pairs) | Simple (fixed size)               |
| **Common Uses**     | Web, file storage                            | Windows, Java, .NET              | Internal processing               |
| **Supported Range** | Full Unicode range                           | Full Unicode range               | Full Unicode range                |


 